{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from chessEngine import ChessEncoder, MLPEngine\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fen_value</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258805</th>\n",
       "      <td>r3k1r1/1p3p2/pbpQp1p1/7p/3PPP2/BPn2R1P/P2q2PK/...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97451</th>\n",
       "      <td>3r1r2/5pkp/4p1p1/p1p5/4NP1N/1qR1P3/5QPP/5RK1 b...</td>\n",
       "      <td>-394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46778</th>\n",
       "      <td>r2q1rk1/p1bpnppp/5n2/1Np5/1PP5/P5P1/4NPKP/R1BQ...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209753</th>\n",
       "      <td>rn1R4/p1p1Q3/1p4p1/1k2p1N1/4B3/8/PPP2PP1/2K4R ...</td>\n",
       "      <td>-8494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27388</th>\n",
       "      <td>r7/8/4p3/4Pk1p/r2Pn1P1/PRPK4/8/R3B3 b - - 0 38</td>\n",
       "      <td>-160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170271</th>\n",
       "      <td>r2qk2r/pp1nnbpp/2p2p2/3pb3/8/1P2P1P1/PBPNNPBP/...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251534</th>\n",
       "      <td>4k2r/p3p1b1/2p3pp/1q3p2/1r1P4/1PQ1PN1P/P4PP1/R...</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207207</th>\n",
       "      <td>1r1qr1k1/1pp1b1pp/p2pb3/4n1P1/8/2N1BN1P/PPPQ1P...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170643</th>\n",
       "      <td>rn1Qk1nr/pbp2pbp/1p2p1p1/4P3/5B2/2N2N2/PPP2PPP...</td>\n",
       "      <td>-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239104</th>\n",
       "      <td>r1b2bnr/pppp1k1p/3qp1p1/3n3B/3P4/P1N2Q2/1PP2PP...</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                fen_value  score\n",
       "258805  r3k1r1/1p3p2/pbpQp1p1/7p/3PPP2/BPn2R1P/P2q2PK/...     35\n",
       "97451   3r1r2/5pkp/4p1p1/p1p5/4NP1N/1qR1P3/5QPP/5RK1 b...   -394\n",
       "46778   r2q1rk1/p1bpnppp/5n2/1Np5/1PP5/P5P1/4NPKP/R1BQ...     78\n",
       "209753  rn1R4/p1p1Q3/1p4p1/1k2p1N1/4B3/8/PPP2PP1/2K4R ...  -8494\n",
       "27388      r7/8/4p3/4Pk1p/r2Pn1P1/PRPK4/8/R3B3 b - - 0 38   -160\n",
       "...                                                   ...    ...\n",
       "170271  r2qk2r/pp1nnbpp/2p2p2/3pb3/8/1P2P1P1/PBPNNPBP/...     34\n",
       "251534  4k2r/p3p1b1/2p3pp/1q3p2/1r1P4/1PQ1PN1P/P4PP1/R...    301\n",
       "207207  1r1qr1k1/1pp1b1pp/p2pb3/4n1P1/8/2N1BN1P/PPPQ1P...      7\n",
       "170643  rn1Qk1nr/pbp2pbp/1p2p1p1/4P3/5B2/2N2N2/PPP2PPP...    -60\n",
       "239104  r1b2bnr/pppp1k1p/3qp1p1/3n3B/3P4/P1N2Q2/1PP2PP...    234\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/fen_analysis.csv').sample(frac=1)[:50000] # This shuffles the rows\n",
    "# df = pd.read_csv('fen_analysis.csv')[:30000] # no shuffle\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_object = ChessEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fen_encodings = []\n",
    "for fen_i in df['fen_value']:\n",
    "    encoded_fen = encoder_object.encode_fen(fen_i)\n",
    "    fen_encodings.append(encoded_fen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(fen_encodings, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9,  0,  0,  ...,  0, 29, 32],\n",
       "        [ 0,  0,  0,  ...,  0, 29, 25],\n",
       "        [ 9,  0,  0,  ...,  0, 34, 34],\n",
       "        ...,\n",
       "        [ 0,  9,  0,  ...,  0, 34, 34],\n",
       "        [ 9, 11,  0,  ...,  0, 38, 29],\n",
       "        [ 9,  0, 10,  ...,  0, 35, 38]], dtype=torch.int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_encodings = []\n",
    "for y_i in df['score']:\n",
    "    # print(y_i)\n",
    "    encoded_score = encoder_object.encode_score(str(y_i))\n",
    "    score_encodings.append(encoded_score)\n",
    "y = torch.tensor(score_encodings, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 200]), torch.Size([50000]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_split = 10000\n",
    "test_split = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X, Y, bs):\n",
    "    \n",
    "    assert isinstance(X, torch.Tensor)\n",
    "    assert isinstance(Y, torch.Tensor)\n",
    "\n",
    "    batch = torch.randint(0, len(X), (bs,))\n",
    "    x = X[batch].to(device)\n",
    "    y = Y[batch].to(device).to(torch.float32)\n",
    "    return x, y\n",
    "# b = get_batch(X, y, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X[:val_split].to(device)\n",
    "y_val = y[:val_split].to(device)\n",
    "X_test = X[val_split:val_split+test_split].to(device)\n",
    "y_test = y[val_split:val_split+test_split].to(device)\n",
    "X = X[val_split+test_split:]\n",
    "y = y[val_split+test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 0.1\n",
    "num_steps = 500\n",
    "warmup_steps = 50\n",
    "bs = len(X)\n",
    "# allowed_error = 100 #\n",
    "d1 = {1:10, 2:20}\n",
    "if bs > len(X): bs = len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " # i accidenly used a smaller lr for scheduler and it worked better, maybe try it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPEngine(embedding_dim=64, bs = bs).to(device)\n",
    "loss_category = nn.MSELoss()\n",
    "optimiser = torch.optim.AdamW(\n",
    "            model.parameters(), \n",
    "            lr = lr,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-3,\n",
    "            weight_decay=1e-5)\n",
    "\n",
    "# Define warm-up and decay\n",
    "def lr_lambda(epoch):\n",
    "    if epoch < warmup_steps:  \n",
    "        return epoch / warmup_steps\n",
    "    else:  # Exponential decay after warm-up\n",
    "        return 0.99 ** (epoch - warmup_steps)\n",
    "\n",
    "scheduler = LambdaLR(optimiser, lr_lambda)\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = {}\n",
    "val_history = {}\n",
    "start_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30000, 200])\n",
      "test 1\u001b[0m\n",
      "\u001b[31mtorch.Size([30000, 12800])\u001b[0m\n",
      "30000\u001b[0m\n",
      "0 :  3141694.5\n",
      "torch.Size([30000, 200])\n",
      "test 1\u001b[0m\n",
      "\u001b[31mtorch.Size([30000, 12800])\u001b[0m\n",
      "30000\u001b[0m\n",
      "1 :  3168970.0\n",
      "torch.Size([30000, 200])\n",
      "test 1\u001b[0m\n",
      "\u001b[31mtorch.Size([30000, 12800])\u001b[0m\n",
      "30000\u001b[0m\n",
      "2 :  3144071.0\n",
      "torch.Size([30000, 200])\n",
      "test 1\u001b[0m\n",
      "\u001b[31mtorch.Size([30000, 12800])\u001b[0m\n",
      "30000\u001b[0m\n",
      "3 :  3197998.0\n",
      "torch.Size([30000, 200])\n",
      "test 1\u001b[0m\n",
      "\u001b[31mtorch.Size([30000, 12800])\u001b[0m\n",
      "30000\u001b[0m\n",
      "4 :  3093024.0\n",
      "torch.Size([30000, 200])\n",
      "test 1\u001b[0m\n",
      "\u001b[31mtorch.Size([30000, 12800])\u001b[0m\n",
      "30000\u001b[0m\n",
      "5 :  3218321.25\n",
      "torch.Size([30000, 200])\n",
      "test 1\u001b[0m\n",
      "\u001b[31mtorch.Size([30000, 12800])\u001b[0m\n",
      "30000\u001b[0m\n",
      "6 :  3069692.25\n",
      "torch.Size([30000, 200])\n",
      "test 1\u001b[0m\n",
      "\u001b[31mtorch.Size([30000, 12800])\u001b[0m\n",
      "30000\u001b[0m\n",
      "7 :  2993385.75\n",
      "torch.Size([30000, 200])\n",
      "test 1\u001b[0m\n",
      "\u001b[31mtorch.Size([30000, 12800])\u001b[0m\n",
      "30000\u001b[0m\n",
      "8 :  3153170.25\n",
      "torch.Size([30000, 200])\n",
      "test 1\u001b[0m\n",
      "\u001b[31mtorch.Size([30000, 12800])\u001b[0m\n",
      "30000\u001b[0m\n",
      "9 :  3147099.5\n",
      "torch.Size([30000, 200])\n",
      "test 1\u001b[0m\n",
      "\u001b[31mtorch.Size([30000, 12800])\u001b[0m\n",
      "30000\u001b[0m\n",
      "10 :  3050829.25\n",
      "torch.Size([30000, 200])\n",
      "test 1\u001b[0m\n",
      "\u001b[31mtorch.Size([30000, 12800])\u001b[0m\n",
      "30000\u001b[0m\n",
      "11 :  3043022.25\n",
      "torch.Size([30000, 200])\n",
      "test 1\u001b[0m\n",
      "\u001b[31mtorch.Size([30000, 12800])\u001b[0m\n",
      "30000\u001b[0m\n",
      "12 :  3247355.75\n",
      "torch.Size([30000, 200])\n",
      "test 1\u001b[0m\n",
      "\u001b[31mtorch.Size([30000, 12800])\u001b[0m\n",
      "30000\u001b[0m\n",
      "13 :  3149536.0\n",
      "torch.Size([30000, 200])\n",
      "test 1\u001b[0m\n",
      "\u001b[31mtorch.Size([30000, 12800])\u001b[0m\n",
      "30000\u001b[0m\n",
      "14 :  3052564.75\n",
      "torch.Size([30000, 200])\n",
      "test 1\u001b[0m\n",
      "\u001b[31mtorch.Size([30000, 12800])\u001b[0m\n",
      "30000\u001b[0m\n",
      "15 :  2996636.25\n",
      "torch.Size([30000, 200])\n",
      "test 1\u001b[0m\n",
      "\u001b[31mtorch.Size([30000, 12800])\u001b[0m\n",
      "30000\u001b[0m\n",
      "16 :  3089285.75\n",
      "torch.Size([30000, 200])\n",
      "test 1\u001b[0m\n",
      "\u001b[31mtorch.Size([30000, 12800])\u001b[0m\n",
      "30000\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# print(f\"Epoch {step_i}, Learning Rate: {scheduler.get_last_lr()}\")\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(tot_step, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tot_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m tot_step \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# validation phase\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(X_val)\u001b[38;5;241m.\u001b[39mview(val_split)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "# train_history = {}\n",
    "# val_history = {}\n",
    "for step_i in range(num_steps):\n",
    "    tot_step = step_i + start_step\n",
    "    optimiser.zero_grad()\n",
    "    x_batch, y_batch = get_batch(X, y, bs) \n",
    "    # print(x_batch, y_batch)\n",
    "    print(x_batch.shape)\n",
    "    y_pred = model(x_batch).view(bs)\n",
    "    # print(y_pred.shape, y_batch.shape)\n",
    "    loss = loss_category(y_pred, y_batch)\n",
    "    # print(loss.item())\n",
    "    train_history[tot_step] = loss.item()\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    scheduler.step()\n",
    "    # print(f\"Epoch {step_i}, Learning Rate: {scheduler.get_last_lr()}\")\n",
    "    print(tot_step, ': ',loss.item())\n",
    "\n",
    "    if tot_step % 100 == 0 and tot_step != 0:\n",
    "        # validation phase\n",
    "        y_pred = model(X_val).view(val_split)\n",
    "        # print(y_pred.shape, y_batch.shape)\n",
    "        loss = loss_category(y_pred, y_val)\n",
    "        # print(loss.item())\n",
    "        val_history[tot_step] = loss.item()\n",
    "\n",
    "start_step += num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'saves/bad_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(train_history.keys())[100:], list(train_history.values())[100:], label='train')\n",
    "# plt.plot(val_history.keys(), val_history.values(), label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(train_history.keys()), list(train_history.values()), label='train')\n",
    "plt.plot(val_history.keys(), val_history.values(), label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# My results\n",
    "At relu, model is stuck around 25k with 3x1000 steps with xavier\n",
    "AT relu, moedl went to 9k and then exploded at 3x1000 steps with kaiming; then at 14k\n",
    "At gelu, model is stuck atound 10k\n",
    "\n",
    "Adam is better than AdamW for this task\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] do inference, and run a partially trained model with the GUI intact\n",
    "- [x] **find a way to fix the fact that our model is giving integer loss\n",
    "- [x] **Fix the bug in initialisation\n",
    "- [ ] implement weights and biases or tensorboard \n",
    "- [ ] improve the model\n",
    "  - [ ] get a better/ bigger dataset\n",
    "  - [ ] hyperparameter and architecture\n",
    "    - [x] better encoding\n",
    "    - [ ] residual connections\n",
    "    - [ ] try adamW after tuning b1 and b2\n",
    "    - [ ] increase embedding dim\n",
    "    - [x] increase neurons in the layers\n",
    "    - [x] increase layers in the network\n",
    "    - [x] change loss function (maybe)\n",
    "    - [ ] try diff learning rate scheduler(trapeziodal)\n",
    "    - [ ] Add regularisation\n",
    "      - [ ] l1,l2\n",
    "      - [x] dropout\n",
    "    - [x] Better initialisation\n",
    "    - [x] diff optimisation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- some issue after the whole architecture was changed in gui file.\n",
    "- also the dataset is bad, look for a new one. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
